---
title: "Infer ASVS with DADA2"
author: "Alicia McElwee"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
    collapsed: no
    smooth_scroll: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "../figures/01_DADA2") # Sends any figure output to this folder
```

# Before you start

## Set my seed
```{r set-seed}
# Setting the seed so randomized choices a reproducible
# Any number can be chosen
set.seed(5318008)

```

## Goals of this file

1. Use raw fastq files and generate quality plots to assess quality of reads.
2. Filter and trim out bad sequences and bases from our sequencing files.
3. Write out fastq files with high quality sequences
4. Evaluate the quality from our filter and trim.
5. Infer errors on forward and reverse reads individually
6. Infer ASVs on forward and reverse reads separately using the error models
7. Merged forward and reverse ASVs into continguous ASVs
8. Generate ASV counts table (ASV counts per sample) `otu_table` input for phyloseq
9.



Output that we need:
1. ASV Count Table: `otu_table`
2. Taxonomy Table: `tax_table`
3. Sample Information: `sample_data` track the reads lost throughout DADA2 workflow

# Installing and Loading Libraries

```{r install-libraries}

#install.packages("devtools")
library(devtools)

#devtools::install_github("benjjneb/dada2")
library(dada2)

#install.packages("tidyverse")
library(tidyverse)

```


# Load Data

```{r load-data}
# Set the raw fastq file path to the raw sequencing files
# Path to the fastq files
raw_fastqs_path <- "data/01_DADA2/01_raw_gzipped_fastqs"
raw_fastqs_path

# What files are in this path? Intuition Check
#list.files(raw_fastqs_path)

# How many files are there?
str(list.files(raw_fastqs_path))

# Create vector of forward reads
forward_reads <- list.files(raw_fastqs_path, pattern = "R1_001.fastq.gz", full.names = TRUE)
  # Intuition Check
head(forward_reads)

# Create vector of reverse reads
reverse_reads <- list.files(raw_fastqs_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
  # Intuition Check
head(reverse_reads)
```


# Raw Quality Plots
```{r raw-quality-plot}
# Randomly select 2 samples from dataset to evaluate
# random_samples <-
random_samples <- sample(1:length(reverse_reads), size = 2)

# Calculate and plot quality of these two samples
plotQualityProfile(forward_reads[random_samples]) +
  labs(title = "Forward Read Raw Quality")
plotQualityProfile(reverse_reads[random_samples]) +
  labs(title = "Reverse Read Raw Quality")
```


# Prepare a placeholder for filtered reads
```{r prep-filtered-sequences}
# vector of our samples, extract sample name from files
# samples <- 
samples <- sapply(strsplit(basename(forward_reads), "_"), `[`,1)
head(samples)

# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# create 2 variables: filtered_F, filtered_R
filtered_forward_reads <- file.path(filtered_fastqs_path, paste0(samples,"_R1_filtered.fastq.gz"))
length(filtered_forward_reads)

filtered_reverse_reads <- file.path(filtered_fastqs_path, paste0(samples,"_R2_filtered.fastq.gz"))
length(filtered_reverse_reads)

```



# Filter and Trim Reads

Parameters of filter and trim **DEPENDS ON THE DATASET**

- `maxN` = number of N bases. Remove all Ns from the data for ASV                   creation
- `maxEE` = max expected errors, quality filtering threshold applied to expected errors. Here, it there's two expected errors its okay, but more than 2 throw away the sequence. Two values, first is for forward reads and second is for reverse reads. Better to do with just 1.

-`trimLeft` = the number of nucleotides to remove from the start of each read, here we are removing first 3 base pairs

-`trunQ` = removes any sequences that have base with quality less than 2

Use controls to check trimming parameters and for contamination

```{r filter-and-trim}
# NOTE: Must alter trim parameters to quality of your own dataset
# Assign a vector to filtered reads
# Trim out poor bases and first 3 bps on F reads
# write out filtered fastq files
filtered_reads <-
  filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(2,2), trimLeft = 3,
              truncQ = 2, rm.phix = TRUE, compress = TRUE)
              #multithread = TRUE

```


# Trimmed Quality Plots

```{r filterTrim-quality-lot}

plotQualityProfile(filtered_forward_reads[random_samples])+
  labs(title = "Trimmed Forward Read Quality")

plotQualityProfile(filtered_reverse_reads[random_samples])+
  labs(title = "Trimmed Forward Read Quality")

```

# Aggregated Trimmed Plots
```{r aggregated-trimed-QC-plots}
# Aggregated all QC Plots
# install and library patchwork
#plotQualityProfile(filtered_forward_reads, aggregate = TRUE) +
#  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE)

```


## Stats on read output from `filterAndTrim`

```{r filterTrim-stats}
# Checking what we outputted from the filterAndTrim command
str(filtered_reads)

# Making into a dataframe
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)

# Calculate stats on how many reads we lost from filter and trimming

filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out)/(median(reads.in))))
```



# Error Modelling

**NOTE:** Works within a single sequencing run. Run separately on each Illumina dataset

```{r learn-errors}
# Goes into each sequence and figures out difference between sequencing error and real biological variation. Starts with most abundant sequence.

# Forward Reads
error_forward_reads <- 
  learnErrors(filtered_forward_reads) # multithread = TRUE if done on own

# Plot Forward
plotErrors(error_forward_reads, nominalQ = TRUE) +
  labs(title = "Forward Read Error Model")

# Reverse Reads
error_reverse_reads <-
  learnErrors(filtered_reverse_reads) # multithread = TRUE if done on own

# Plot Reverse
plotErrors(error_reverse_reads, nominalQ = TRUE) +
  labs(tittle = "Reverse Read Error")

```


# Infer ASVs

Note that this is happening separately on the forward and reverse reads! This is unique to DADA2


```{r infer-ASVs}
# Infer Forward ASVs
dada_forward <- dada(filtered_forward_reads,
                     err = error_forward_reads,
                     multithread = TRUE)  

# Infer Reverse ASVs
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads,
                     multithread = TRUE)
```

# Merge Forward & Reverse ASVs

drep is filtered reads for forward and reverse

```{r merge-ASVs}
# merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filtered_forward_reads,
                          dada_reverse, filtered_reverse_reads,
                          verbose = TRUE)

            # Verbose makes it so output will also go in html file when it gets                   knitted

# Evaluate the output
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)
```


# Generate ASV Count Table

```{r generate-ASV-table}
# Create the ASV count table, has the counts of each ASV in each sample
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Mar will send code so we can write out the file to data/01_DADA2

```



# Session Information
```{r session-info}
# Ensure reproducibility by telling software versions
devtools::session_info()

```
